<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Concrete AI safety problems | wlsc_Tech_blog</title>
<meta name="keywords" content="Paper, Safety">
<meta name="description" content="The “Concrete AI safety problems” paper by _Dario Amodei (Google Brain), Chris Olah (Google Brain), Jacob Steinhardt (Stanford University), Paul Christiano (UC Berkeley), John Schulman (OpenAI), Dan Mané (Google Brain) _suggests a new approach to the Machine Learning (ML) and Artificial Intelligence (AI) research, which focuses more on productivity of forward-looking applications while building cutting-edge AI systems.
A number of key problems considered in the paper as well as their descriptions are listed below. In the paper authors also elaborate on how to approach each of the given problem.">
<meta name="author" content="Wladimir Schmidt">
<link rel="canonical" href="https://blog.wlsc.de/2016/06/22/concrete-ai-safety-problems/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css" integrity="sha256-j&#43;ECM6cGvIfy4Is8&#43;XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://blog.wlsc.de/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://blog.wlsc.de/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://blog.wlsc.de/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://blog.wlsc.de/apple-touch-icon.png">
<link rel="mask-icon" href="https://blog.wlsc.de/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://blog.wlsc.de/2016/06/22/concrete-ai-safety-problems/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://blog.wlsc.de/2016/06/22/concrete-ai-safety-problems/">
  <meta property="og:site_name" content="wlsc_Tech_blog">
  <meta property="og:title" content="Concrete AI safety problems">
  <meta property="og:description" content="The “Concrete AI safety problems” paper by _Dario Amodei (Google Brain), Chris Olah (Google Brain), Jacob Steinhardt (Stanford University), Paul Christiano (UC Berkeley), John Schulman (OpenAI), Dan Mané (Google Brain) _suggests a new approach to the Machine Learning (ML) and Artificial Intelligence (AI) research, which focuses more on productivity of forward-looking applications while building cutting-edge AI systems.
A number of key problems considered in the paper as well as their descriptions are listed below. In the paper authors also elaborate on how to approach each of the given problem.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2016-06-22T11:20:06+00:00">
    <meta property="article:modified_time" content="2016-06-22T11:20:06+00:00">
    <meta property="article:tag" content="Paper">
    <meta property="article:tag" content="Safety">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Concrete AI safety problems">
<meta name="twitter:description" content="The “Concrete AI safety problems” paper by _Dario Amodei (Google Brain), Chris Olah (Google Brain), Jacob Steinhardt (Stanford University), Paul Christiano (UC Berkeley), John Schulman (OpenAI), Dan Mané (Google Brain) _suggests a new approach to the Machine Learning (ML) and Artificial Intelligence (AI) research, which focuses more on productivity of forward-looking applications while building cutting-edge AI systems.
A number of key problems considered in the paper as well as their descriptions are listed below. In the paper authors also elaborate on how to approach each of the given problem.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://blog.wlsc.de/post/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Concrete AI safety problems",
      "item": "https://blog.wlsc.de/2016/06/22/concrete-ai-safety-problems/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Concrete AI safety problems",
  "name": "Concrete AI safety problems",
  "description": "The “Concrete AI safety problems” paper by _Dario Amodei (Google Brain), Chris Olah (Google Brain), Jacob Steinhardt (Stanford University), Paul Christiano (UC Berkeley), John Schulman (OpenAI), Dan Mané (Google Brain) _suggests a new approach to the Machine Learning (ML) and Artificial Intelligence (AI) research, which focuses more on productivity of forward-looking applications while building cutting-edge AI systems.\nA number of key problems considered in the paper as well as their descriptions are listed below. In the paper authors also elaborate on how to approach each of the given problem.\n",
  "keywords": [
    "Paper", "Safety"
  ],
  "articleBody": "The “Concrete AI safety problems” paper by _Dario Amodei (Google Brain), Chris Olah (Google Brain), Jacob Steinhardt (Stanford University), Paul Christiano (UC Berkeley), John Schulman (OpenAI), Dan Mané (Google Brain) _suggests a new approach to the Machine Learning (ML) and Artificial Intelligence (AI) research, which focuses more on productivity of forward-looking applications while building cutting-edge AI systems.\nA number of key problems considered in the paper as well as their descriptions are listed below. In the paper authors also elaborate on how to approach each of the given problem.\nAvoiding Negative Side Eﬀects: How can we ensure that our cleaning robot will not\ndisturb the environment in negative ways while pursuing its goals, e.g. by knocking over a\nvase because it can clean faster by doing so? Can we do this without manually specifying\neverything the robot should not disturb?\nAvoiding Reward Hacking: How can we ensure that the cleaning robot won’t game its reward function? For example, if we reward the robot for achieving an environment free of\nmesses, it might disable its vision so that it won’t ﬁnd any messes, or cover over messes with\nmaterials it can’t see through, or simply hide when humans are around so they can’t tell it\nabout new types of messes.\nScalable Oversight: How can we eﬃciently ensure that the cleaning robot respects aspects of\nthe objective that are too expensive to be frequently evaluated during training? For instance, it\nshould throw out things that are unlikely to belong to anyone, but put aside things that might\nbelong to someone (it should handle stray candy wrappers diﬀerently from stray cellphones).\nAsking the humans involved whether they lost anything can serve as a check on this, but this\ncheck might have to be relatively infrequent – can the robot ﬁnd a way to do the right thing\ndespite limited information?\nSafe Exploration: How do we ensure that the cleaning robot doesn’t make exploratory\nmoves with very bad repercussions? For example, the robot should experiment with mopping\nstrategies, but putting a wet mop in an electrical outlet is a very bad idea.\nRobustness to Distributional Shift: How do we ensure that the cleaning robot recognizes,\nand behaves robustly, when in an environment diﬀerent from its training environment? For\nexample, heuristics it learned for cleaning factory workﬂoors may be outright dangerous in an\noﬃce.\nSource: Concrete Problems in AI Safety\n",
  "wordCount" : "395",
  "inLanguage": "en",
  "datePublished": "2016-06-22T11:20:06Z",
  "dateModified": "2016-06-22T11:20:06Z",
  "author":{
    "@type": "Person",
    "name": "Wladimir Schmidt"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://blog.wlsc.de/2016/06/22/concrete-ai-safety-problems/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "wlsc_Tech_blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://blog.wlsc.de/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://blog.wlsc.de/" accesskey="h" title="wlsc_Tech_blog (Alt + H)">wlsc_Tech_blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://wlsc.de/" title="..:index:..">
                    <span>..:index:..</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Concrete AI safety problems
    </h1>
    <div class="post-meta"><span title='2016-06-22 11:20:06 +0000 UTC'>June 22, 2016</span>&nbsp;·&nbsp;Wladimir Schmidt

</div>
  </header> 
  <div class="post-content"><p>The <strong>“Concrete AI safety problems”</strong> paper by _Dario Amodei (Google Brain), Chris Olah (Google Brain), Jacob Steinhardt (Stanford University), Paul Christiano (UC Berkeley), John Schulman (OpenAI), Dan Mané (Google Brain) _suggests a new approach to the Machine Learning (ML) and Artificial Intelligence (AI) research, which focuses more on productivity of forward-looking applications while building cutting-edge AI systems.</p>
<p>A number of key problems considered in the paper as well as their descriptions are listed below. In the paper authors also elaborate on how to approach each of the given problem.</p>
<ul>
<li>
<p><strong>Avoiding Negative Side Eﬀects:</strong> How can we ensure that our cleaning robot will not</p>
<p>disturb the environment in negative ways while pursuing its goals, e.g. by knocking over a</p>
<p>vase because it can clean faster by doing so? Can we do this without manually specifying</p>
<p>everything the robot should not disturb?</p>
<ul>
<li><strong>Avoiding Reward Hacking:</strong> How can we ensure that the cleaning robot won’t game its</li>
</ul>
<p>reward function? For example, if we reward the robot for achieving an environment free of</p>
<p>messes, it might disable its vision so that it won’t ﬁnd any messes, or cover over messes with</p>
<p>materials it can’t see through, or simply hide when humans are around so they can’t tell it</p>
<p>about new types of messes.</p>
<ul>
<li>
<p><strong>Scalable Oversight:</strong> How can we eﬃciently ensure that the cleaning robot respects aspects of</p>
<p>the objective that are too expensive to be frequently evaluated during training? For instance, it</p>
<p>should throw out things that are unlikely to belong to anyone, but put aside things that might</p>
<p>belong to someone (it should handle stray candy wrappers diﬀerently from stray cellphones).</p>
<p>Asking the humans involved whether they lost anything can serve as a check on this, but this</p>
<p>check might have to be relatively infrequent – can the robot ﬁnd a way to do the right thing</p>
<p>despite limited information?</p>
</li>
<li>
<p><strong>Safe Exploration:</strong> How do we ensure that the cleaning robot doesn’t make exploratory</p>
<p>moves with very bad repercussions? For example, the robot should experiment with mopping</p>
<p>strategies, but putting a wet mop in an electrical outlet is a very bad idea.</p>
</li>
<li>
<p><strong>Robustness to Distributional Shift:</strong> How do we ensure that the cleaning robot recognizes,</p>
<p>and behaves robustly, when in an environment diﬀerent from its training environment? For</p>
<p>example, heuristics it learned for cleaning factory workﬂoors may be outright dangerous in an</p>
<p>oﬃce.</p>
</li>
</ul>
</li>
</ul>
<p><em>Source: <a href="https://arxiv.org/abs/1606.06565" target="_blank">Concrete Problems in AI Safety</a></em></p>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://blog.wlsc.de/tags/paper/">Paper</a></li>
      <li><a href="https://blog.wlsc.de/tags/safety/">Safety</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://blog.wlsc.de/">wlsc_Tech_blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
