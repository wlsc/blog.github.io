<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Apple releases its first AI paper | wlsc_Tech_blog</title>
<meta name="keywords" content="Apple, GAN, Generative Adversarial Networks, Paper">
<meta name="description" content="
  Learning from Simulated and Unsupervised Images through Adversarial Training


  


  The first paper from Apple company regarding Artificial Intelligence with Deep Learning is published!

">
<meta name="author" content="Wladimir Schmidt">
<link rel="canonical" href="https://blog.wlsc.de/2017/01/01/apple-releases-its-first-ai-paper/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css" integrity="sha256-j&#43;ECM6cGvIfy4Is8&#43;XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://blog.wlsc.de/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://blog.wlsc.de/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://blog.wlsc.de/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://blog.wlsc.de/apple-touch-icon.png">
<link rel="mask-icon" href="https://blog.wlsc.de/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://blog.wlsc.de/2017/01/01/apple-releases-its-first-ai-paper/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://blog.wlsc.de/2017/01/01/apple-releases-its-first-ai-paper/">
  <meta property="og:site_name" content="wlsc_Tech_blog">
  <meta property="og:title" content="Apple releases its first AI paper">
  <meta property="og:description" content=" Learning from Simulated and Unsupervised Images through Adversarial Training The first paper from Apple company regarding Artificial Intelligence with Deep Learning is published! ">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="post">
    <meta property="article:published_time" content="2017-01-01T19:35:17+00:00">
    <meta property="article:modified_time" content="2017-01-01T19:35:17+00:00">
    <meta property="article:tag" content="Apple">
    <meta property="article:tag" content="GAN">
    <meta property="article:tag" content="Generative Adversarial Networks">
    <meta property="article:tag" content="Paper">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Apple releases its first AI paper">
<meta name="twitter:description" content="
  Learning from Simulated and Unsupervised Images through Adversarial Training


  


  The first paper from Apple company regarding Artificial Intelligence with Deep Learning is published!

">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://blog.wlsc.de/post/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Apple releases its first AI paper",
      "item": "https://blog.wlsc.de/2017/01/01/apple-releases-its-first-ai-paper/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Apple releases its first AI paper",
  "name": "Apple releases its first AI paper",
  "description": " Learning from Simulated and Unsupervised Images through Adversarial Training The first paper from Apple company regarding Artificial Intelligence with Deep Learning is published! ",
  "keywords": [
    "Apple", "GAN", "Generative Adversarial Networks", "Paper"
  ],
  "articleBody": " Learning from Simulated and Unsupervised Images through Adversarial Training The first paper from Apple company regarding Artificial Intelligence with Deep Learning is published! Abstract With recent progress in graphics, it has become more tractable to train models on synthetic images, potentially avoiding the need for expensive annotations. However, learning from synthetic images may not achieve the desired performance due to a gap between synthetic and real image distributions. To reduce this gap, we propose Simulated+Unsupervised (S+U) learning, where the task is to learn a model to improve the realism of a simulator’s output using unlabeled real data, while preserving the annotation information from the simulator. We develop a method for S+U learning that uses an adversarial network similar to Generative Adversarial Networks (GANs), but with synthetic images as inputs instead of random vectors. We make several key modifications to the standard GAN algorithm to preserve annotations, avoid artifacts and stabilize training: (i) a ‘self-regularization’ term, (ii) a local adversarial loss, and (iii) updating the discriminator using a history of refined images. We show that this enables generation of highly realistic images, which we demonstrate both qualitatively and with a user study. We quantitatively evaluate the generated images by training models for gaze estimation and hand pose estimation. We show a significant improvement over using synthetic images, and achieve state-of-the-art results on the MPIIGaze dataset without any labeled real data.\nSource: https://arxiv.org/abs/1612.07828\n",
  "wordCount" : "231",
  "inLanguage": "en",
  "datePublished": "2017-01-01T19:35:17Z",
  "dateModified": "2017-01-01T19:35:17Z",
  "author":{
    "@type": "Person",
    "name": "Wladimir Schmidt"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://blog.wlsc.de/2017/01/01/apple-releases-its-first-ai-paper/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "wlsc_Tech_blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://blog.wlsc.de/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://blog.wlsc.de/" accesskey="h" title="wlsc_Tech_blog (Alt + H)">wlsc_Tech_blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://wlsc.de/" title="..:index:..">
                    <span>..:index:..</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Apple releases its first AI paper
    </h1>
    <div class="post-meta"><span title='2017-01-01 19:35:17 +0000 UTC'>January 1, 2017</span>&nbsp;·&nbsp;Wladimir Schmidt

</div>
  </header> 
  <div class="post-content"><h2 class="title mathjax" style="text-align: center;">
  Learning from Simulated and Unsupervised Images through Adversarial Training
</h2>
<p style="text-align: center;">
  <a href="/images/2017/01/apple_first_paper.jpg"><img class="aligncenter wp-image-256 size-large" src="/images/2017/01/apple_first_paper-1024x560.jpg" alt="Apple first AI paper" width="750" height="410" srcset="/images/2017/01/apple_first_paper-1024x560.jpg 1024w, /images/2017/01/apple_first_paper-300x164.jpg 300w, /images/2017/01/apple_first_paper-768x420.jpg 768w, /images/2017/01/apple_first_paper.jpg 1028w" sizes="(max-width: 750px) 100vw, 750px" /></a>
</p>
<p style="text-align: left;">
  The first paper from Apple company regarding Artificial Intelligence with Deep Learning <a href="https://arxiv.org/abs/1612.07828" target="_blank">is published</a>!
</p>
<p style="text-align: left;">
</p>
<h4 style="text-align: left;">
  Abstract
</h4>
<p>With recent progress in graphics, it has become more tractable to train models on synthetic images, potentially avoiding the need for expensive annotations. However, learning from synthetic images may not achieve the desired performance due to a gap between synthetic and real image distributions. To reduce this gap, we propose Simulated+Unsupervised (S+U) learning, where the task is to learn a model to improve the realism of a simulator’s output using unlabeled real data, while preserving the annotation information from the simulator. We develop a method for S+U learning that uses an adversarial network similar to Generative Adversarial Networks (GANs), but with synthetic images as inputs instead of random vectors. We make several key modifications to the standard GAN algorithm to preserve annotations, avoid artifacts and stabilize training: (i) a ‘self-regularization’ term, (ii) a local adversarial loss, and (iii) updating the discriminator using a history of refined images. We show that this enables generation of highly realistic images, which we demonstrate both qualitatively and with a user study. We quantitatively evaluate the generated images by training models for gaze estimation and hand pose estimation. We show a significant improvement over using synthetic images, and achieve state-of-the-art results on the MPIIGaze dataset without any labeled real data.</p>
<p><em>Source:</em>  <a href="https://arxiv.org/abs/1612.07828" target="_blank"><a href="https://arxiv.org/abs/1612.07828">https://arxiv.org/abs/1612.07828</a></a></p>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://blog.wlsc.de/tags/apple/">Apple</a></li>
      <li><a href="https://blog.wlsc.de/tags/gan/">GAN</a></li>
      <li><a href="https://blog.wlsc.de/tags/generative-adversarial-networks/">Generative Adversarial Networks</a></li>
      <li><a href="https://blog.wlsc.de/tags/paper/">Paper</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://blog.wlsc.de/">wlsc_Tech_blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
